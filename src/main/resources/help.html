<!DOCTYPE html>

<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
<head>
    <meta charset="utf-8" />
    <title>Bitmanager's extensions</title>
    <style type="text/css">
      h2,h3 {margin-top: 2em;margin-bottom: 0.1em;}
      td ul {margin-top: 0px; margin-bottom: 0px; }
      .border {border: 1px solid red;}
      .vert {vertical-align: top;}
      .key {vertical-align: top; font-weight: bold}
    </style>
</head>
<body>
<h1 id="top"><a href="http://bitmanager.nl">&#x25E4;</a> Bitmanager's extensions to ElasticSearch</h1>
This document describes the extensions that can be used from ElasticSearch.
Following plugins are contained:
    <ul>
        <li><a href="#version">Version</a><br />API to check versions and other things across the cluster</li>
        <li><a href="#similarity">Custom similarity</a><br />Custom similarity provider that tries to score tokens more subtile</li>
        <li><a href="#view">View</a><br />View Lucene's representation of a record. (Re-inverts the document from index data) </li>
        <li><a href="#cache">Cache dump</a><br />Dump the filter caches for every node</li>
        <li><a href="#fieldsdump">Field dump</a><br />Dump Lucene's information about a field</li>
    </ul>

<h2 id="version">Version checking</h2>
As a diagnosis measure the plugin supports a REST API to get the loaded plugin versions of all nodes. <a href='/_bm/_version?pretty=true'>http://localhost:9200/_bm/_version</a>.
<br />It returns something like:
<pre>
   {
  ....ES heading...
      "pluginVersion" : "1.0.3",
        "allVersionsOK" : true,
        "activeNodes" : 1,
        "nodeVersions" : [ {
          "node" : "[Norrin Radd][N1cNIQ2KTvmhi4vHh89njQ][baard3][inet[/192.168.0.102:9300]]",
          "version" : "1.0.3",
          "location" : "file:/E:/Elastic/elasticsearch-1.3.1/plugins/bitmanager-ext/bitmanager-elasticsearch-plugin-1.3.1.jar",
          "fileSize" : 7605776,
          "fileDate" : "2014-08-08T13:44:23.678Z",
          "esVersion" : "1.3.1",
          "settings" : {
            "path.home" : "E:\\Elastic\\elasticsearch-1.3.1",
            "index.number_of_replicas" : "0",
            "index.number_of_shards" : "2",
            "cluster.name" : "baard3",
            "name" : "Norrin Radd",
            "path.logs" : "E:/Elastic/elasticsearch-1.3.1/logs"
          }
     }
}
</pre>
One can simply test for allVersionsOK==true. This value is false when:
<ul>
   <li>No nodes are available</li>
   <li>At least 1 node has no or a different version</li>
   <li>The fileSize/fileDate differs</li>
</ul>
<p><a href="#top">Back to the top</a></p>

<h2 id="similarity">Bounded similarity</h2>
This custom similarity provider supplies a custom tf/idf similarity that tries to score individual tokens around 1. The score can be a bit higher or lower, depending on the tf or idf. 
It is possible to completely switch of the idf part or the tf part or both.
The idea behind scoring around 1.0 is that it is more easy to apply boosts to tokens like applying a boost of 0.5 for stemmed query tokens. Also boosting documents after the search tends to be easier and more clear.
Native Lucene similarities have more explosive score ranges and this makes it really hard to reasonable downweight tokens.
<p>
You can define a named custom similarity provider in your index like:</p>
<pre>
{
   "similarity" : {
      "my_similarity" : {
         "type" : "nl.bitmanager.elasticsearch.similarity.BoundedSimilarity.Provider",
         "discountOverlaps": false,
         "maxIdf": 0.2,
         "maxTf": 0.2,
         "biasTf": 0.6
      }
   }   
}</pre>
The resulting score is calculated as 1 + idfValue + tfValue. So, if both values are switched off, the score will be just 1.<br/>
Following settings are possible:
<table cellspacing="5">
   <tr><td class="key">discountOverlaps</td><td>Determines whether overlap tokens (Tokens with 0 position increment) are ignored when computing norm. By default this is true, meaning overlap tokens do not count when computing norms.</td></tr>
    <tr>
        <td class="key">maxIdf</td>
        <td>
            The maximum value that should be used for the idf-part of the score.
            <br />If this value is 0, the idf part is completely ignored and always 0.
            Otherwise the idf-part is between 0 and maxIdf. Note that a negative value will reverse the workings of idf and prefer tokens that occur in lots of documents. This can sometimes be usefull.
        </td>
    </tr>
    <tr>
        <td class="key">maxTf</td>
        <td>
            The maximum value that should be used for the tf-part of the score.
            <br />If this value is 0, the tf part is completely ignored and always 0.
            Otherwise the tf-part is between 0 and maxTf. Note that a negative value will reverse the workings of tf and prefer matches with more tokens in the field.
        </td>
    </tr>
   <tr><td class="key">biasTf</td><td>The raw tf-score is computed from log (biasTf + #matchting terms) / log (biasTf + #terms in the field) 
      <br />Note that the #terms in the field is extracted from the norms, so setting omit_norms=true in the mapping will force a #terms=1.
      <br /></td></tr>
</table>   
<p><a href="#top">Back to the top</a></p>

<h2 id="view">View Lucene's representation of a record</h2>
    This API shows the content of a document as it is known to Lucene.<br/>
<ul>
    <li>curl -XGET '<a href="/index/type/id/_view?pretty=true">http://localhost:9200/{index}/{type}/{id}/_view</a></li>
</ul>
<p>
    Following extra parameters are supported at this url:
    <table cellspacing="5">
        <tr><td class="key">docid:</td><td>The docid of the document to dump. Override the computed docid</td></tr>
        <tr><td class="key">shard:</td><td>The id of the shard. Used together with docid</td></tr>
        <tr><td class="key">field:</td><td>Outputs only data for the specified field</td></tr>
        <tr><td class="key">field_expr:</td><td>Same as field, but now via a regex.</td></tr>
        <tr><td class="key">output:</td><td>stored|indexed|docvalues (or combination)</td></tr>
        <tr><td class="key">output_lvl:</td><td>values &gt; 0 will return more (debug) information</td></tr>
    </table>
    <br/>
    By default the API 're-creates' the document from the the index. This is done by enumerating all terms from the index, if the term has an entry for the document it is collected in the doument.
    It should be clear that this is a very costly operation. <br />
    To prevent this, one can limit the output to only the stored fields and the docvalues by specifiying ?output=stored,docvalues.
    <br /><br />
    By specifying docid and or shard, it is possible to override the dumped document, depending on the parms:
    <ul>
        <li>no docid, no shard<br />The dumped document is denoted by [index/type/id].</li>
        <li>docid specified, no shard<br />The dumped document is [docid], the shard is derived from [index/type/id].</li>
        <li>docid and shard specified<br />The dumped document is [docid] in shard [shard]. [index/type/id] is not used.</li>
    </ul> 
    If no fields are supplied and a dump of the indexed fields is requested, all fields are dumped.
</p>
<p><a href="#top">Back to the top</a></p>

    <h2 id="cache">Dump the filter caches for every node</h2>
    This API dumps all cached filters/queries on a node.
    <ul>
        <li>curl -XGET '<a href="/_cache/dump?pretty=true">http://localhost:9200/_cache/dump</a></li>
    </ul>
    <p>
        Following extra parameters are supported at this url:
        <table cellspacing="5">
            <tr><td class="key">index_expr:</td><td>Regex to extract the index name from the cache key. It is in the form &lt;expr&gt;/&lt;repl&gt;. The repl part supports $ placeholders. Defaults to '', collecting all info under the artificial index name '_ALL'.</td></tr>
            <tr><td class="key">sort_query:</td><td>By default the output is ordered by the #used bytes. If sort_query=true is specified, the output is sorted on query.</td></tr>
        </table>
        <br />
        This is an experimental API, since it relies on internal Elasticsearch and Lucene structures. The API uses reflection to get access to private fields. If any of those fields cannot be found or cannot be accessed, it returns an exception.
        The output will contain the toString() versions of the queries and their space requirements, collected by index name. The index name is get by executing a toString() on the cache key, which gives most of the time a reasonable indication of the index.
        The raw names are always outputted. These names can be customised by using an index_expr parameter.
    </p>
    <p><a href="#top">Back to the top</a></p>



    <h2 id="fieldsdump">Dump Lucene's information about a field</h2>
    <ul>
        <li>curl -XGET '<a href="/{index}/_fields/dump?pretty=true">http://localhost:9200/{index}/_fields/dump</a></li>
    </ul>
    <p><a href="#top">Back to the top</a></p>


<h2 id="termlist">Termlist</h2>
This termlist plugin was based on the termlist plugin from Jorge Prante.
(https://github.com/jprante/elasticsearch-index-termlist)

<br />The following api is supported:
<ul>
   <li>curl -XGET '<a href="/[index]/_termlist?sort=sort&filter=&pretty=true">http://localhost:9200/{index}/_termlist</a></li>
   <li>curl -XGET '<a href="/[index]/_termlist/[field]?sort=sort&_filter=&pretty=true">http://localhost:9200/{index}/_termlist/{field}</a></li>
</ul>
For conveniance, POSTs are supported as well, nothing will be done with the supplied content.<br />
Following extra parms are supported: ?<a href="#termlist-filter">filter</a>=...
   &amp;<a href="#termlist-sort">sort</a>=...
   &amp;<a href="#termlist-resultlimit">result_limit</a>=...
   &amp;<a href="#termlist-mincount">min_count</a>=...
   &amp;<a href="#termlist-maxcount">max_count</a>=...
   &amp;<a href="#termlist-replexpr">repl_expr</a>=...
   &amp;<a href="#termlist-term">term</a>=...
   
<p>{index} can be a ,-separated list of index names to limit the termlist generation.<br />
If no {index} is specified, all indexes will be queried.</p>

<p>{field} can be a ,-separated list of field names to limit the termlist generation.<br />
If no {field} is specified, the definitions of all fields in the selected indexes will be dumped, but no termlist will be generated.</p>

The plugin will supply a list of terms (tokens) with their accumilated counts. Like:
<pre>
     "terms": [
         {
            "t": "aap",
            "c": 23
         },
         {
            "t": "noot",
            "c": 212
         },
         etc...
      }  
</pre>
 <p>Note that the counts are accumilated over fields and indexes, without taking into account the indexes could have records in common.
So the returned counts &gt;= the actual counts.</p>

<h3 id="termlist-sort">Sorting</h3>
The list is sorted on term by default. The sort can be changed by supplying an extra param on the url:<br />
<ul><li>?sort=[count | -count]</li></ul>

<h3>Limiting the resultset</h3>
The returned result can be limited by supplying one or more params on the url:
<ul>
<li id="termlist-filter">?filter=&lt;regex&gt;         returns only terms that match the expression</li>
<li id="termlist-resultlimit">?result_limit=&lt;count&gt;    returns only the top &lt;count&gt; items of the list (after sorting!)</li>
<li id="termlist-mincount">?min_count=&lt;min&gt;         returns only items that occur &gt;= min times. If 0&lt;min&lt;1, min is recalculated by multiplying it by the max term count.</li>
<li id="termlist-maxcount">?max_count=&lt;max&gt;         returns only items that occur &lt;= max times. If 0&lt;max&lt;1, max is recalculated by multiplying it by the max term count.</li>
</ul>
<h3 id="termlist-replexpr">Collision detection</h3>
<p>To check wether terms collide after mapping terms, use the following param:<br />
   ?replExpr=&lt;expr/repl&gt;   forinstance: 'ae/e' replaces a term 'maedchen' into 'madchen'</p>
After the replacement a check is done if the resulting term was already in the index.
Output is like:
<pre>
   {
      "term": {
         "t": "almhuette",
         "c": 1
      },
      "coll": {
         "t": "almhutte",
         "c": 19
      }
   },
   etc...   
</pre>         
<h3 id="termlist-term">Term occurrence</h3>
To get the fields where a term occurs, apply the ?term=&lt;term&gt; to the url.<br />
If this param is found, a list of fields where the term occurs is returned.

<h3 style="color:red">Warning</h3>
The term list is built internally for each selected shard as a sorted set of strings/counts.<br />
These sets are streamed back to the node where the requeste came in, and are accumulated on that node.<br />
You should be aware that this will result in a large amount of requested heap memory and may result in out of memory situations that can render your Elasticsearch cluster unusable until it is restarted.<br />
It is best to limit your resultset by supplying resultset limiting params on the url (see above)

<p><a href="#top">Back to the top</a></p>
<h2 id="ngramex_filter">NGramex token filter</h2>
The NGramex token filter is based on Lucene's NGram token filter with version 4.1.<br />
This version was emitting token with the correct position, making it possible to highlight them correctly (instead of the whole term).<br />
Besides that, the filter has the ability to modify the tokens by
<ul>
   <li>Appending the position of the token to the token itself.<br />
      So, abcd will be emitted like ab0, bc1, cd2</li>
   <li>Prepending 0 or more first characters from the term.<br />
      Suppose that we prepend 1 char, then abcd will be emitted like ab, abc, acd</li>
   <li>Starting from a specified opffset.<br />
      Suppose that we start at offset 1, then abcd will be emitted like bc, cd</li>
</ul> 

<p><a href="#top">Back to the top</a></p>
<h2 id="ngram_highlighter">NGram highlighter</h2>
The NGram highlighter will highlight the longest contigious match (or matches) from the matched ngrams. It can be specified like:
<pre>
{
   "highlight": {
      "fields": {
         "text4": {
            "type": "ngram", 
            "options":  {
               "analyzer": "standard", 
               "debug": "true"
            }
         }
      }
   }
}</pre>
The options are optional. If no analyzer is supplied, the index-analyzer for the field will be used
    <p><a href="#top">Back to the top</a></p>


</body>
</html>